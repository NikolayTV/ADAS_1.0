{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolay/.pyenv/versions/3.7.3/envs/main/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from openvino.inference_engine import IECore\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class OpenVino_student_action(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        model_path = '../src/models/person-detection-action-recognition-0005/FP32/person-detection-action-recognition-0005'\n",
    "\n",
    "        # Prep for face detection\n",
    "        ie = IECore()\n",
    "\n",
    "        net_action = ie.read_network(model=model_path+'.xml', weights=model_path+'.bin')\n",
    "        self.input_name_action  = next(iter(net_action.inputs))                              # Input blob name\n",
    "        self.input_shape_action = net_action.inputs[self.input_name_action].shape                     # [1,3,60,60]\n",
    "        self.out_name_action    = next(iter(net_action.outputs))                             # Output blob name\n",
    "        self.out_shape_action   = net_action.outputs[self.out_name_action].shape                      # [1,70]\n",
    "        self.exec_net_action    = ie.load_network(network=net_action, device_name='CPU', num_requests=1)\n",
    "        del net_action\n",
    "\n",
    "    def predict(self, img):\n",
    "\n",
    "        img_processed = cv2.resize(img, (self.input_shape_action[3], self.input_shape_action[2]))\n",
    "        img_processed = img_processed.transpose((2, 0, 1))\n",
    "        img_processed = img_processed.reshape(self.input_shape_action)\n",
    "\n",
    "        res_action = self.exec_net_action.infer(inputs={self.input_name_action: img_processed})\n",
    "\n",
    "        return res_action\n",
    "    \n",
    "model = OpenVino_student_action()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolay/.pyenv/versions/3.7.3/envs/main/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model_path = '../src/models/person-detection-action-recognition-0005/FP32/person-detection-action-recognition-0005'\n",
    "\n",
    "# Prep for face detection\n",
    "ie = IECore()\n",
    "\n",
    "net_action = ie.read_network(model=model_path+'.xml', weights=model_path+'.bin')\n",
    "input_name_action  = next(iter(net_action.inputs))                              # Input blob name\n",
    "input_shape_action = net_action.inputs[input_name_action].shape                     # [1,3,60,60]\n",
    "out_name_action    = next(iter(net_action.outputs))                             # Output blob name\n",
    "out_shape_action   = net_action.outputs[out_name_action].shape                      # [1,70]\n",
    "exec_net_action    = ie.load_network(network=net_action, device_name='CPU', num_requests=1)\n",
    "del net_action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mbox/priorbox'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_name_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 17200]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_shape_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_name_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../../data/pic1.png')\n",
    "res = model.predict(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mbox/priorbox', 'mbox_loc1/out/conv/flat', 'mbox_main_conf/out/conv/flat/softmax/flat', 'out/anchor1', 'out/anchor2', 'out/anchor3', 'out/anchor4'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.arrowedLine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in [1, 2, 3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
